{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "from utils import bandits, snowden\n",
    "reload(utils)\n",
    "reload(utils.bandits)\n",
    "reload(utils.snowden)\n",
    "from utils.bandits import exact_gittins\n",
    "\n",
    "from templates import neural as neural_agent\n",
    "reload(neural_agent)\n",
    "\n",
    "neural_agent_class = neural_agent.NeuralAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions/nagiss/20201226/ ['sessions/nagiss/20201226/8389416.json', 'sessions/nagiss/20201226/8528396.json', 'sessions/nagiss/20201226/8415103.json', 'sessions/nagiss/20201226/8354920.json', 'sessions/nagiss/20201226/8499335.json', 'sessions/nagiss/20201226/8441958.json', 'sessions/nagiss/20201226/8377070.json', 'sessions/nagiss/20201226/8513521.json', 'sessions/nagiss/20201226/8364900.json', 'sessions/nagiss/20201226/8428032.json', 'sessions/nagiss/20201226/8485987.json', 'sessions/nagiss/20201226/8455991.json', 'sessions/nagiss/20201226/8471153.json', 'sessions/nagiss/20201226/8401973.json']\n"
     ]
    }
   ],
   "source": [
    "datasets = snowden.collect_dataset_from_dir(neural_agent_class, 'sessions/nagiss/20201226/', 1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25987, 36), (1999, 36))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].X.shape, datasets[1].X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean before resampling: 0.31915957978989495\n",
      "mean after resampling: 0.5\n",
      "mean before resampling: 0.3166583291645823\n",
      "mean after resampling: 0.5\n"
     ]
    }
   ],
   "source": [
    "train = snowden.resample_eq(datasets[0])\n",
    "val = snowden.resample_eq(datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16588, 36), (1266, 36))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X.shape, val.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(train, val, model_ff, epochs=5, batch_size=64, shuffle=True, freq=10,lr=1e-3):          \n",
    "    np.random.seed(1)\n",
    "    ids_nn = np.arange(train.X.shape[0])\n",
    "\n",
    "#     criterion = nn.BCELoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_ff.parameters(), lr=lr)\n",
    "\n",
    "    time_for_print_loss = lambda i: (i + 1) % freq == 0\n",
    "    \n",
    "\n",
    "    for epoch in np.arange(epochs):\n",
    "        np.random.shuffle(ids_nn)\n",
    "        X_train_shuffled = train.X[ids_nn]\n",
    "        y_train_shuffled = train.y[ids_nn]\n",
    "        \n",
    "        model_ff.train(True)\n",
    "\n",
    "        for b in np.arange(0, X_train_shuffled.shape[0], batch_size):\n",
    "            X_batch = torch.FloatTensor(X_train_shuffled[b:b+batch_size])\n",
    "            y_batch = torch.FloatTensor(y_train_shuffled[b:b+batch_size])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred_logits = model_ff(X_batch).reshape(-1)\n",
    "\n",
    "            loss = criterion(y_pred_logits, y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (b // batch_size + 1) % freq == 0:\n",
    "                print('train loss in %d epoch in %d batch: %.5f' %\n",
    "                  (epoch + 1, b // batch_size + 1, loss.item()))\n",
    "\n",
    "        val_loss = 0\n",
    "        its = 0\n",
    "        model_ff.train(False)\n",
    "        for b in np.arange(0, val.X.shape[0], batch_size):\n",
    "            its += 1\n",
    "            X_batch = torch.FloatTensor(val.X[b:b+batch_size])\n",
    "            y_batch = torch.FloatTensor(val.y[b:b+batch_size])\n",
    "            with torch.no_grad():\n",
    "                y_pred_logits = model_ff(X_batch).reshape(-1)\n",
    "            loss = criterion(y_pred_logits, y_batch)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= its\n",
    "        print('val loss in %d epoch: %.5f' % (epoch + 1, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNWithCusomFeatures(nn.Module):\n",
    "    def __init__(self, INPUT_F, DROP_P, H):\n",
    "        super().__init__()\n",
    "        INPUT_F_C = INPUT_F + 2 * INPUT_F\n",
    "        self.model_ff =  nn.Sequential(\n",
    "            nn.BatchNorm1d(INPUT_F_C),\n",
    "            nn.Dropout(DROP_P),\n",
    "            nn.Linear(INPUT_F_C, H),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(DROP_P),\n",
    "            nn.Linear(H, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lg = torch.log(1 + torch.abs(x))\n",
    "        sn = torch.sin(x)\n",
    "        input_x = torch.cat([x, lg, sn], axis=1)\n",
    "        return self.model_ff(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 1 epoch in 40 batch: 0.695\n",
      "train loss in 1 epoch in 80 batch: 0.680\n",
      "train loss in 1 epoch in 120 batch: 0.696\n",
      "train loss in 1 epoch in 160 batch: 0.661\n",
      "train loss in 1 epoch in 200 batch: 0.702\n",
      "train loss in 1 epoch in 240 batch: 0.665\n",
      "train loss in 1 epoch in 280 batch: 0.645\n",
      "train loss in 1 epoch in 320 batch: 0.680\n",
      "train loss in 1 epoch in 360 batch: 0.683\n",
      "train loss in 1 epoch in 400 batch: 0.670\n",
      "train loss in 1 epoch in 440 batch: 0.689\n",
      "train loss in 1 epoch in 480 batch: 0.630\n",
      "val loss in 1 epoch: 0.657\n",
      "train loss in 2 epoch in 40 batch: 0.648\n",
      "train loss in 2 epoch in 80 batch: 0.672\n",
      "train loss in 2 epoch in 120 batch: 0.593\n",
      "train loss in 2 epoch in 160 batch: 0.685\n",
      "train loss in 2 epoch in 200 batch: 0.696\n",
      "train loss in 2 epoch in 240 batch: 0.631\n",
      "train loss in 2 epoch in 280 batch: 0.621\n",
      "train loss in 2 epoch in 320 batch: 0.661\n",
      "train loss in 2 epoch in 360 batch: 0.696\n",
      "train loss in 2 epoch in 400 batch: 0.569\n",
      "train loss in 2 epoch in 440 batch: 0.673\n",
      "train loss in 2 epoch in 480 batch: 0.736\n",
      "val loss in 2 epoch: 0.644\n",
      "train loss in 3 epoch in 40 batch: 0.713\n",
      "train loss in 3 epoch in 80 batch: 0.654\n",
      "train loss in 3 epoch in 120 batch: 0.570\n",
      "train loss in 3 epoch in 160 batch: 0.605\n",
      "train loss in 3 epoch in 200 batch: 0.610\n",
      "train loss in 3 epoch in 240 batch: 0.625\n",
      "train loss in 3 epoch in 280 batch: 0.605\n",
      "train loss in 3 epoch in 320 batch: 0.574\n",
      "train loss in 3 epoch in 360 batch: 0.659\n",
      "train loss in 3 epoch in 400 batch: 0.626\n",
      "train loss in 3 epoch in 440 batch: 0.681\n",
      "train loss in 3 epoch in 480 batch: 0.601\n",
      "val loss in 3 epoch: 0.639\n",
      "train loss in 4 epoch in 40 batch: 0.565\n",
      "train loss in 4 epoch in 80 batch: 0.577\n",
      "train loss in 4 epoch in 120 batch: 0.671\n",
      "train loss in 4 epoch in 160 batch: 0.648\n",
      "train loss in 4 epoch in 200 batch: 0.619\n",
      "train loss in 4 epoch in 240 batch: 0.769\n",
      "train loss in 4 epoch in 280 batch: 0.708\n",
      "train loss in 4 epoch in 320 batch: 0.683\n",
      "train loss in 4 epoch in 360 batch: 0.598\n",
      "train loss in 4 epoch in 400 batch: 0.592\n",
      "train loss in 4 epoch in 440 batch: 0.583\n",
      "train loss in 4 epoch in 480 batch: 0.679\n",
      "val loss in 4 epoch: 0.638\n",
      "train loss in 5 epoch in 40 batch: 0.617\n",
      "train loss in 5 epoch in 80 batch: 0.671\n",
      "train loss in 5 epoch in 120 batch: 0.603\n",
      "train loss in 5 epoch in 160 batch: 0.592\n",
      "train loss in 5 epoch in 200 batch: 0.620\n",
      "train loss in 5 epoch in 240 batch: 0.635\n",
      "train loss in 5 epoch in 280 batch: 0.701\n",
      "train loss in 5 epoch in 320 batch: 0.629\n",
      "train loss in 5 epoch in 360 batch: 0.612\n",
      "train loss in 5 epoch in 400 batch: 0.629\n",
      "train loss in 5 epoch in 440 batch: 0.667\n",
      "train loss in 5 epoch in 480 batch: 0.591\n",
      "val loss in 5 epoch: 0.637\n",
      "train loss in 6 epoch in 40 batch: 0.551\n",
      "train loss in 6 epoch in 80 batch: 0.655\n",
      "train loss in 6 epoch in 120 batch: 0.557\n",
      "train loss in 6 epoch in 160 batch: 0.637\n",
      "train loss in 6 epoch in 200 batch: 0.636\n",
      "train loss in 6 epoch in 240 batch: 0.588\n",
      "train loss in 6 epoch in 280 batch: 0.606\n",
      "train loss in 6 epoch in 320 batch: 0.660\n",
      "train loss in 6 epoch in 360 batch: 0.591\n",
      "train loss in 6 epoch in 400 batch: 0.587\n",
      "train loss in 6 epoch in 440 batch: 0.636\n",
      "train loss in 6 epoch in 480 batch: 0.658\n",
      "val loss in 6 epoch: 0.637\n",
      "train loss in 7 epoch in 40 batch: 0.651\n",
      "train loss in 7 epoch in 80 batch: 0.632\n",
      "train loss in 7 epoch in 120 batch: 0.636\n",
      "train loss in 7 epoch in 160 batch: 0.696\n",
      "train loss in 7 epoch in 200 batch: 0.652\n",
      "train loss in 7 epoch in 240 batch: 0.659\n",
      "train loss in 7 epoch in 280 batch: 0.660\n",
      "train loss in 7 epoch in 320 batch: 0.551\n",
      "train loss in 7 epoch in 360 batch: 0.624\n",
      "train loss in 7 epoch in 400 batch: 0.703\n",
      "train loss in 7 epoch in 440 batch: 0.631\n",
      "train loss in 7 epoch in 480 batch: 0.634\n",
      "val loss in 7 epoch: 0.636\n"
     ]
    }
   ],
   "source": [
    "INPUT_F = 36\n",
    "H = 256\n",
    "DROP_P = 0.05\n",
    "\n",
    "model = NNWithCusomFeatures(INPUT_F, DROP_P, H)\n",
    "\n",
    "learn(train, val, model, freq=40, batch_size=32,lr=1e-5, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/nagiss_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 1 epoch in 40 batch: 0.246\n",
      "train loss in 1 epoch in 80 batch: 0.244\n",
      "train loss in 1 epoch in 120 batch: 0.248\n",
      "train loss in 1 epoch in 160 batch: 0.233\n",
      "train loss in 1 epoch in 200 batch: 0.242\n",
      "train loss in 1 epoch in 240 batch: 0.238\n",
      "train loss in 1 epoch in 280 batch: 0.239\n",
      "train loss in 1 epoch in 320 batch: 0.235\n",
      "train loss in 1 epoch in 360 batch: 0.245\n",
      "train loss in 1 epoch in 400 batch: 0.240\n",
      "train loss in 1 epoch in 440 batch: 0.248\n",
      "train loss in 1 epoch in 480 batch: 0.216\n",
      "val loss in 1 epoch: 0.234\n",
      "train loss in 2 epoch in 40 batch: 0.234\n",
      "train loss in 2 epoch in 80 batch: 0.233\n",
      "train loss in 2 epoch in 120 batch: 0.199\n",
      "train loss in 2 epoch in 160 batch: 0.247\n",
      "train loss in 2 epoch in 200 batch: 0.256\n",
      "train loss in 2 epoch in 240 batch: 0.219\n",
      "train loss in 2 epoch in 280 batch: 0.221\n",
      "train loss in 2 epoch in 320 batch: 0.227\n",
      "train loss in 2 epoch in 360 batch: 0.239\n",
      "train loss in 2 epoch in 400 batch: 0.194\n",
      "train loss in 2 epoch in 440 batch: 0.240\n",
      "train loss in 2 epoch in 480 batch: 0.272\n",
      "val loss in 2 epoch: 0.227\n",
      "train loss in 3 epoch in 40 batch: 0.251\n",
      "train loss in 3 epoch in 80 batch: 0.228\n",
      "train loss in 3 epoch in 120 batch: 0.198\n",
      "train loss in 3 epoch in 160 batch: 0.208\n",
      "train loss in 3 epoch in 200 batch: 0.209\n",
      "train loss in 3 epoch in 240 batch: 0.221\n",
      "train loss in 3 epoch in 280 batch: 0.213\n",
      "train loss in 3 epoch in 320 batch: 0.201\n",
      "train loss in 3 epoch in 360 batch: 0.231\n",
      "train loss in 3 epoch in 400 batch: 0.220\n",
      "train loss in 3 epoch in 440 batch: 0.244\n",
      "train loss in 3 epoch in 480 batch: 0.213\n",
      "val loss in 3 epoch: 0.224\n",
      "train loss in 4 epoch in 40 batch: 0.194\n",
      "train loss in 4 epoch in 80 batch: 0.192\n",
      "train loss in 4 epoch in 120 batch: 0.241\n",
      "train loss in 4 epoch in 160 batch: 0.233\n",
      "train loss in 4 epoch in 200 batch: 0.214\n",
      "train loss in 4 epoch in 240 batch: 0.279\n",
      "train loss in 4 epoch in 280 batch: 0.260\n",
      "train loss in 4 epoch in 320 batch: 0.244\n",
      "train loss in 4 epoch in 360 batch: 0.205\n",
      "train loss in 4 epoch in 400 batch: 0.205\n",
      "train loss in 4 epoch in 440 batch: 0.196\n",
      "train loss in 4 epoch in 480 batch: 0.236\n",
      "val loss in 4 epoch: 0.223\n",
      "train loss in 5 epoch in 40 batch: 0.213\n",
      "train loss in 5 epoch in 80 batch: 0.243\n",
      "train loss in 5 epoch in 120 batch: 0.207\n",
      "train loss in 5 epoch in 160 batch: 0.204\n",
      "train loss in 5 epoch in 200 batch: 0.217\n",
      "train loss in 5 epoch in 240 batch: 0.230\n",
      "train loss in 5 epoch in 280 batch: 0.260\n",
      "train loss in 5 epoch in 320 batch: 0.225\n",
      "train loss in 5 epoch in 360 batch: 0.216\n",
      "train loss in 5 epoch in 400 batch: 0.223\n",
      "train loss in 5 epoch in 440 batch: 0.238\n",
      "train loss in 5 epoch in 480 batch: 0.196\n",
      "val loss in 5 epoch: 0.223\n"
     ]
    }
   ],
   "source": [
    "# mse loss\n",
    "INPUT_F = 36\n",
    "H = 256\n",
    "DROP_P = 0.05\n",
    "\n",
    "model = NNWithCusomFeatures(INPUT_F, DROP_P, H)\n",
    "\n",
    "learn(train, val, model, freq=40, batch_size=32,lr=1e-5, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/nagiss_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632.0 611.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "676.0 642.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "599.0 543.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "624.0 621.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "606.0 639.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "607.0 591.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "609.0 552.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "626.0 606.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "630.0 603.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n",
      "615.0 615.0 tmp/b_0.9817500612110714.py tmp/b_0.6737446183327064.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.012154502623372141,\n",
       " 20.1,\n",
       " 25.34738645304482,\n",
       " 0.9,\n",
       " 'tmp/b_0.9817500612110714.py',\n",
       " 'tmp/b_0.6737446183327064.py',\n",
       " array([632., 676., 599., 624., 606., 607., 609., 626., 630., 615.]),\n",
       " array([611., 642., 543., 621., 639., 591., 552., 606., 603., 615.]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_only_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678.0 661.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "700.0 695.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "664.0 660.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "597.0 615.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "659.0 696.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "601.0 581.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "626.0 623.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "536.0 607.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "580.0 550.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n",
      "636.0 562.0 tmp/b_0.054213267519393926.py tmp/b_0.236142134925876.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8180618145466889,\n",
       " 2.7,\n",
       " 37.11616898334202,\n",
       " 0.7,\n",
       " 'tmp/b_0.054213267519393926.py',\n",
       " 'tmp/b_0.236142134925876.py',\n",
       " array([678., 700., 664., 597., 659., 601., 626., 536., 580., 636.]),\n",
       " array([661., 695., 660., 615., 696., 581., 623., 607., 550., 562.]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_only_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text= utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.0 685.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "717.0 717.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "691.0 721.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "629.0 671.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "624.0 662.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "677.0 627.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "579.0 572.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "594.0 621.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "617.0 593.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n",
      "629.0 634.0 tmp/b_0.4681855452475341.py tmp/b_0.815911715993058.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.31907279631279994,\n",
       " -8.9,\n",
       " 28.246946737656444,\n",
       " 0.4,\n",
       " 'tmp/b_0.4681855452475341.py',\n",
       " 'tmp/b_0.815911715993058.py',\n",
       " array([657., 717., 691., 629., 624., 677., 579., 594., 617., 629.]),\n",
       " array([685., 717., 721., 671., 662., 627., 572., 621., 593., 634.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_only_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text= utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all nagiss games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions/nagiss/20201226_v2/ ['sessions/nagiss/20201226_v2/7994638.json', 'sessions/nagiss/20201226_v2/7991093.json', 'sessions/nagiss/20201226_v2/7988820.json', 'sessions/nagiss/20201226_v2/8386716.json', 'sessions/nagiss/20201226_v2/8038792.json', 'sessions/nagiss/20201226_v2/8233786.json', 'sessions/nagiss/20201226_v2/8073493.json', 'sessions/nagiss/20201226_v2/8012231.json', 'sessions/nagiss/20201226_v2/7995268.json', 'sessions/nagiss/20201226_v2/8046220.json', 'sessions/nagiss/20201226_v2/8321309.json', 'sessions/nagiss/20201226_v2/8102725.json', 'sessions/nagiss/20201226_v2/8146617.json', 'sessions/nagiss/20201226_v2/7986639.json', 'sessions/nagiss/20201226_v2/8029737.json', 'sessions/nagiss/20201226_v2/8089900.json', 'sessions/nagiss/20201226_v2/8354985.json', 'sessions/nagiss/20201226_v2/7995644.json', 'sessions/nagiss/20201226_v2/7998867.json', 'sessions/nagiss/20201226_v2/8257767.json', 'sessions/nagiss/20201226_v2/7992085.json', 'sessions/nagiss/20201226_v2/7987842.json', 'sessions/nagiss/20201226_v2/8172893.json', 'sessions/nagiss/20201226_v2/8201003.json', 'sessions/nagiss/20201226_v2/8009354.json', 'sessions/nagiss/20201226_v2/7988519.json', 'sessions/nagiss/20201226_v2/7987183.json', 'sessions/nagiss/20201226_v2/7992694.json', 'sessions/nagiss/20201226_v2/7991811.json', 'sessions/nagiss/20201226_v2/8464420.json', 'sessions/nagiss/20201226_v2/8186631.json', 'sessions/nagiss/20201226_v2/8054877.json', 'sessions/nagiss/20201226_v2/8249308.json', 'sessions/nagiss/20201226_v2/8273034.json', 'sessions/nagiss/20201226_v2/7987567.json', 'sessions/nagiss/20201226_v2/8371128.json', 'sessions/nagiss/20201226_v2/8060412.json', 'sessions/nagiss/20201226_v2/8541194.json', 'sessions/nagiss/20201226_v2/8481316.json', 'sessions/nagiss/20201226_v2/7994974.json', 'sessions/nagiss/20201226_v2/8132606.json', 'sessions/nagiss/20201226_v2/7989777.json', 'sessions/nagiss/20201226_v2/7992382.json', 'sessions/nagiss/20201226_v2/8160880.json', 'sessions/nagiss/20201226_v2/8005498.json', 'sessions/nagiss/20201226_v2/8337440.json', 'sessions/nagiss/20201226_v2/8008069.json', 'sessions/nagiss/20201226_v2/8304463.json', 'sessions/nagiss/20201226_v2/7994017.json', 'sessions/nagiss/20201226_v2/7995939.json', 'sessions/nagiss/20201226_v2/8510303.json', 'sessions/nagiss/20201226_v2/8433263.json', 'sessions/nagiss/20201226_v2/7996231.json', 'sessions/nagiss/20201226_v2/7996548.json', 'sessions/nagiss/20201226_v2/8449014.json', 'sessions/nagiss/20201226_v2/7988184.json', 'sessions/nagiss/20201226_v2/8215761.json', 'sessions/nagiss/20201226_v2/7993014.json', 'sessions/nagiss/20201226_v2/7989458.json', 'sessions/nagiss/20201226_v2/7990100.json', 'sessions/nagiss/20201226_v2/8288389.json', 'sessions/nagiss/20201226_v2/7991414.json', 'sessions/nagiss/20201226_v2/7994342.json', 'sessions/nagiss/20201226_v2/8417594.json', 'sessions/nagiss/20201226_v2/7991731.json', 'sessions/nagiss/20201226_v2/8402256.json', 'sessions/nagiss/20201226_v2/8002300.json', 'sessions/nagiss/20201226_v2/8495892.json', 'sessions/nagiss/20201226_v2/8557211.json', 'sessions/nagiss/20201226_v2/8073192.json', 'sessions/nagiss/20201226_v2/8118585.json', 'sessions/nagiss/20201226_v2/8016051.json', 'sessions/nagiss/20201226_v2/7993371.json', 'sessions/nagiss/20201226_v2/7989156.json', 'sessions/nagiss/20201226_v2/7990750.json', 'sessions/nagiss/20201226_v2/8021586.json', 'sessions/nagiss/20201226_v2/7993701.json', 'sessions/nagiss/20201226_v2/7990443.json', 'sessions/nagiss/20201226_v2/8079696.json', 'sessions/nagiss/20201226_v2/7987514.json', 'sessions/nagiss/20201226_v2/8525948.json']\n",
      "error while parse session sessions/nagiss/20201226_v2/8354985.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/7991811.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/8054877.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/8005498.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/7995939.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/7991414.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/8002300.json : \n"
     ]
    }
   ],
   "source": [
    "datasets = snowden.collect_dataset_from_dir(neural_agent_class, 'sessions/nagiss/20201226_v2/', 1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133933, 36), (13993, 36))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].X.shape, datasets[1].X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean before resampling: 0.31643433657127074\n",
      "mean after resampling: 0.5\n",
      "mean before resampling: 0.3148002572714929\n",
      "mean after resampling: 0.5\n"
     ]
    }
   ],
   "source": [
    "train = snowden.resample_eq(datasets[0])\n",
    "val = snowden.resample_eq(datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84762, 36), (8810, 36))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X.shape, val.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NNWithCusomFeatures(nn.Module):\n",
    "#     def __init__(self, INPUT_F, DROP_P, H):\n",
    "#         super().__init__()\n",
    "#         INPUT_F_C = INPUT_F + 2 * INPUT_F\n",
    "#         self.model_ff_1 =  nn.Sequential(\n",
    "#             nn.BatchNorm1d(INPUT_F_C),\n",
    "#             nn.Dropout(DROP_P),\n",
    "#             nn.Linear(INPUT_F_C, H),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Dropout(DROP_P)\n",
    "#         )\n",
    "#         self.model_ff_2 =  nn.Sequential(\n",
    "#             nn.Linear(H, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         lg = torch.log(1 + torch.abs(x))\n",
    "#         sn = torch.sin(x)\n",
    "#         input_x = torch.cat([x, lg, sn], axis=1)\n",
    "#         out1 =  self.model_ff_1(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 1 epoch in 500 batch: 0.24326\n",
      "train loss in 1 epoch in 1000 batch: 0.23294\n",
      "train loss in 1 epoch in 1500 batch: 0.25006\n",
      "train loss in 1 epoch in 2000 batch: 0.20686\n",
      "train loss in 1 epoch in 2500 batch: 0.21678\n",
      "val loss in 1 epoch: 0.22331\n",
      "train loss in 2 epoch in 500 batch: 0.26177\n",
      "train loss in 2 epoch in 1000 batch: 0.19144\n",
      "train loss in 2 epoch in 1500 batch: 0.17022\n",
      "train loss in 2 epoch in 2000 batch: 0.23671\n",
      "train loss in 2 epoch in 2500 batch: 0.22735\n",
      "val loss in 2 epoch: 0.22240\n",
      "train loss in 3 epoch in 500 batch: 0.18364\n",
      "train loss in 3 epoch in 1000 batch: 0.25060\n",
      "train loss in 3 epoch in 1500 batch: 0.25504\n",
      "train loss in 3 epoch in 2000 batch: 0.21704\n",
      "train loss in 3 epoch in 2500 batch: 0.20117\n",
      "val loss in 3 epoch: 0.22189\n",
      "train loss in 4 epoch in 500 batch: 0.17385\n",
      "train loss in 4 epoch in 1000 batch: 0.22882\n",
      "train loss in 4 epoch in 1500 batch: 0.22496\n",
      "train loss in 4 epoch in 2000 batch: 0.20567\n",
      "train loss in 4 epoch in 2500 batch: 0.22413\n",
      "val loss in 4 epoch: 0.22164\n",
      "train loss in 5 epoch in 500 batch: 0.18633\n",
      "train loss in 5 epoch in 1000 batch: 0.23591\n",
      "train loss in 5 epoch in 1500 batch: 0.19090\n",
      "train loss in 5 epoch in 2000 batch: 0.20379\n",
      "train loss in 5 epoch in 2500 batch: 0.21904\n",
      "val loss in 5 epoch: 0.22131\n"
     ]
    }
   ],
   "source": [
    "# mse loss\n",
    "INPUT_F = 36\n",
    "H = 256\n",
    "DROP_P = 0.05\n",
    "\n",
    "model = NNWithCusomFeatures(INPUT_F, DROP_P, H)\n",
    "\n",
    "learn(train, val, model, freq=500, batch_size=32,lr=1e-5, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/nagiss_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619.0 538.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "552.0 574.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "641.0 652.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "631.0 601.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "703.0 651.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "643.0 666.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "617.0 628.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "607.0 574.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "638.0 660.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n",
      "618.0 632.0 tmp/b_0.5394941534468733.py tmp/b_0.9677390896108925.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4021809806045401,\n",
       " 9.3,\n",
       " 35.105697543276364,\n",
       " 0.4,\n",
       " 'tmp/b_0.5394941534468733.py',\n",
       " 'tmp/b_0.9677390896108925.py',\n",
       " array([619., 552., 641., 631., 703., 643., 617., 607., 638., 618.]),\n",
       " array([538., 574., 652., 601., 651., 666., 628., 574., 660., 632.]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v3\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_only_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions/nagiss/20201226_v2/ ['sessions/nagiss/20201226_v2/7994638.json', 'sessions/nagiss/20201226_v2/7991093.json', 'sessions/nagiss/20201226_v2/7988820.json', 'sessions/nagiss/20201226_v2/8386716.json', 'sessions/nagiss/20201226_v2/8038792.json', 'sessions/nagiss/20201226_v2/8233786.json', 'sessions/nagiss/20201226_v2/8073493.json', 'sessions/nagiss/20201226_v2/8012231.json', 'sessions/nagiss/20201226_v2/7995268.json', 'sessions/nagiss/20201226_v2/8046220.json', 'sessions/nagiss/20201226_v2/8321309.json', 'sessions/nagiss/20201226_v2/8102725.json', 'sessions/nagiss/20201226_v2/8146617.json', 'sessions/nagiss/20201226_v2/7986639.json', 'sessions/nagiss/20201226_v2/8029737.json', 'sessions/nagiss/20201226_v2/8089900.json', 'sessions/nagiss/20201226_v2/8354985.json', 'sessions/nagiss/20201226_v2/7995644.json', 'sessions/nagiss/20201226_v2/7998867.json', 'sessions/nagiss/20201226_v2/8257767.json', 'sessions/nagiss/20201226_v2/7992085.json', 'sessions/nagiss/20201226_v2/7987842.json', 'sessions/nagiss/20201226_v2/8172893.json', 'sessions/nagiss/20201226_v2/8201003.json', 'sessions/nagiss/20201226_v2/8009354.json', 'sessions/nagiss/20201226_v2/7988519.json', 'sessions/nagiss/20201226_v2/7987183.json', 'sessions/nagiss/20201226_v2/7992694.json', 'sessions/nagiss/20201226_v2/7991811.json', 'sessions/nagiss/20201226_v2/8464420.json', 'sessions/nagiss/20201226_v2/8186631.json', 'sessions/nagiss/20201226_v2/8054877.json', 'sessions/nagiss/20201226_v2/8249308.json', 'sessions/nagiss/20201226_v2/8273034.json', 'sessions/nagiss/20201226_v2/7987567.json', 'sessions/nagiss/20201226_v2/8371128.json', 'sessions/nagiss/20201226_v2/8060412.json', 'sessions/nagiss/20201226_v2/8541194.json', 'sessions/nagiss/20201226_v2/8481316.json', 'sessions/nagiss/20201226_v2/7994974.json', 'sessions/nagiss/20201226_v2/8132606.json', 'sessions/nagiss/20201226_v2/7989777.json', 'sessions/nagiss/20201226_v2/7992382.json', 'sessions/nagiss/20201226_v2/8160880.json', 'sessions/nagiss/20201226_v2/8005498.json', 'sessions/nagiss/20201226_v2/8337440.json', 'sessions/nagiss/20201226_v2/8008069.json', 'sessions/nagiss/20201226_v2/8304463.json', 'sessions/nagiss/20201226_v2/7994017.json', 'sessions/nagiss/20201226_v2/7995939.json', 'sessions/nagiss/20201226_v2/8510303.json', 'sessions/nagiss/20201226_v2/8433263.json', 'sessions/nagiss/20201226_v2/7996231.json', 'sessions/nagiss/20201226_v2/7996548.json', 'sessions/nagiss/20201226_v2/8449014.json', 'sessions/nagiss/20201226_v2/7988184.json', 'sessions/nagiss/20201226_v2/8215761.json', 'sessions/nagiss/20201226_v2/7993014.json', 'sessions/nagiss/20201226_v2/7989458.json', 'sessions/nagiss/20201226_v2/7990100.json', 'sessions/nagiss/20201226_v2/8288389.json', 'sessions/nagiss/20201226_v2/7991414.json', 'sessions/nagiss/20201226_v2/7994342.json', 'sessions/nagiss/20201226_v2/8417594.json', 'sessions/nagiss/20201226_v2/7991731.json', 'sessions/nagiss/20201226_v2/8402256.json', 'sessions/nagiss/20201226_v2/8002300.json', 'sessions/nagiss/20201226_v2/8495892.json', 'sessions/nagiss/20201226_v2/8557211.json', 'sessions/nagiss/20201226_v2/8073192.json', 'sessions/nagiss/20201226_v2/8118585.json', 'sessions/nagiss/20201226_v2/8016051.json', 'sessions/nagiss/20201226_v2/7993371.json', 'sessions/nagiss/20201226_v2/7989156.json', 'sessions/nagiss/20201226_v2/7990750.json', 'sessions/nagiss/20201226_v2/8021586.json', 'sessions/nagiss/20201226_v2/7993701.json', 'sessions/nagiss/20201226_v2/7990443.json', 'sessions/nagiss/20201226_v2/8079696.json', 'sessions/nagiss/20201226_v2/7987514.json', 'sessions/nagiss/20201226_v2/8525948.json', 'sessions/nagiss/20201226_v2/.ipynb_checkpoints/8002300-checkpoint.json']\n",
      "error while parse session sessions/nagiss/20201226_v2/8354985.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/7991811.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/8054877.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/8005498.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/7995939.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/7991414.json : \n",
      "error while parse session sessions/nagiss/20201226_v2/8002300.json : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error while parse session sessions/nagiss/20201226_v2/.ipynb_checkpoints/8002300-checkpoint.json : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [12:54<00:00, 11.56s/it]\n",
      "100%|██████████| 7/7 [01:19<00:00, 11.38s/it]\n"
     ]
    }
   ],
   "source": [
    "#with mean features\n",
    "\n",
    "datasets = snowden.collect_dataset_from_dir(neural_agent_class, 'sessions/nagiss/20201226_v2/', 1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133933, 72), (13993, 72))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].X.shape, datasets[1].X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean before resampling: 0.3157548923715589\n",
      "mean after resampling: 0.5\n",
      "mean before resampling: 0.3213035088973058\n",
      "mean after resampling: 0.5\n"
     ]
    }
   ],
   "source": [
    "train = snowden.resample_eq(datasets[0])\n",
    "val = snowden.resample_eq(datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 1 epoch in 500 batch: 0.21463\n",
      "train loss in 1 epoch in 1000 batch: 0.21573\n",
      "train loss in 1 epoch in 1500 batch: 0.21318\n",
      "train loss in 1 epoch in 2000 batch: 0.23660\n",
      "train loss in 1 epoch in 2500 batch: 0.24215\n",
      "val loss in 1 epoch: 0.22201\n",
      "train loss in 2 epoch in 500 batch: 0.23591\n",
      "train loss in 2 epoch in 1000 batch: 0.20482\n",
      "train loss in 2 epoch in 1500 batch: 0.23344\n",
      "train loss in 2 epoch in 2000 batch: 0.16600\n",
      "train loss in 2 epoch in 2500 batch: 0.21033\n",
      "val loss in 2 epoch: 0.22148\n"
     ]
    }
   ],
   "source": [
    "# mse loss\n",
    "INPUT_F = 72\n",
    "H = 256\n",
    "DROP_P = 0.05\n",
    "\n",
    "model = NNWithCusomFeatures(INPUT_F, DROP_P, H)\n",
    "\n",
    "learn(train, val, model, freq=500, batch_size=32,lr=1e-5, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/nagiss_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667.0 754.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "592.0 654.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "594.0 554.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "635.0 670.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "568.0 609.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "575.0 603.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "603.0 606.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "668.0 660.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "613.0 595.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n",
      "598.0 582.0 tmp/b_0.6401838703031111.py tmp/b_0.7108320478829738.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14605214374251638,\n",
       " -17.4,\n",
       " 37.852873074576515,\n",
       " 0.4,\n",
       " 'tmp/b_0.6401838703031111.py',\n",
       " 'tmp/b_0.7108320478829738.py',\n",
       " array([667., 592., 594., 635., 568., 575., 603., 668., 613., 598.]),\n",
       " array([754., 654., 554., 670., 609., 603., 606., 660., 595., 582.]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v4\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_only_nagiss=True\", \"\")\n",
    "neural_default = utils.bandits.neural.format(\"use_mean=False\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=neural_default),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # v4 vs default + mean features\n",
    "# utils.bandits.compare(\n",
    "#     utils.bandits.Agent(text=neural_with_nagiss),\n",
    "#     utils.bandits.Agent(text=utils.bandits.neural),\n",
    "#     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637.0 624.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "652.0 693.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "600.0 628.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "597.0 611.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "646.0 634.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "624.0 627.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "595.0 599.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "605.0 596.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "664.0 672.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n",
      "628.0 608.0 tmp/b_0.00783945348032078.py tmp/b_0.08316848165655322.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.44715964885505466,\n",
       " -4.4,\n",
       " 18.30409790183608,\n",
       " 0.4,\n",
       " 'tmp/b_0.00783945348032078.py',\n",
       " 'tmp/b_0.08316848165655322.py',\n",
       " array([637., 652., 600., 597., 646., 624., 595., 605., 664., 628.]),\n",
       " array([624., 693., 628., 611., 634., 627., 599., 596., 672., 608.]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v3 as feature\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_feature_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617.0 640.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "644.0 619.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "679.0 694.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "645.0 617.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "601.0 629.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "628.0 617.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "639.0 634.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "651.0 658.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "736.0 647.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n",
      "586.0 588.0 tmp/b_0.2329175121645335.py tmp/b_0.9947346263005474.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41522101422787383,\n",
       " 8.3,\n",
       " 32.21505859066533,\n",
       " 0.5,\n",
       " 'tmp/b_0.2329175121645335.py',\n",
       " 'tmp/b_0.9947346263005474.py',\n",
       " array([617., 644., 679., 645., 601., 628., 639., 651., 736., 586.]),\n",
       " array([640., 619., 694., 617., 629., 617., 634., 658., 647., 588.]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2 as feature\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_feature_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627.0 664.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "563.0 601.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "579.0 583.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "673.0 630.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "648.0 693.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "633.0 632.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "625.0 616.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "607.0 577.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "625.0 655.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n",
      "617.0 651.0 tmp/b_0.6232887914692327.py tmp/b_0.7812314428145001.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25859498040269646,\n",
       " -10.5,\n",
       " 29.391325250828686,\n",
       " 0.4,\n",
       " 'tmp/b_0.6232887914692327.py',\n",
       " 'tmp/b_0.7812314428145001.py',\n",
       " array([627., 563., 579., 673., 648., 633., 625., 607., 625., 617.]),\n",
       " array([664., 601., 583., 630., 693., 632., 616., 577., 655., 651.]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v4 as feature\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_feature_nagiss,use_mean=True,True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=utils.bandits.neural),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538.0 550.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "633.0 611.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "589.0 594.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "614.0 638.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "631.0 664.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "656.0 644.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "529.0 583.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "610.0 635.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "641.0 625.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n",
      "664.0 632.0 tmp/b_0.03981686451690292.py tmp/b_0.8435219654502392.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38850022498604,\n",
       " -7.1,\n",
       " 26.036320784627,\n",
       " 0.4,\n",
       " 'tmp/b_0.03981686451690292.py',\n",
       " 'tmp/b_0.8435219654502392.py',\n",
       " array([538., 633., 589., 614., 631., 656., 529., 610., 641., 664.]),\n",
       " array([550., 611., 594., 638., 664., 644., 583., 635., 625., 632.]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2 as feature vs only v2\n",
    "neural_with_nagiss = utils.bandits.neural.format(\"use_feature_nagiss=True\", \"\")\n",
    "neural_with_only_nagiss = utils.bandits.neural.format(\"use_only_nagiss=True\", \"\")\n",
    "utils.bandits.compare(\n",
    "    utils.bandits.Agent(text=neural_with_nagiss),\n",
    "    utils.bandits.Agent(text=neural_with_only_nagiss),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
